{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tree import DecisionTreeNode,CARTRegressor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "\n",
    "class GBDTClassfier(CARTRegressor):\n",
    "    def __init__(self,learning_rate=1,n_trees=None,min_samples_leaf=None,max_depth=None):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_trees = n_trees\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_depth = max_depth\n",
    "        self.trees=[]\n",
    "        \n",
    "    def fit(self,data):\n",
    "        data=np.array(data)\n",
    "        label=np.array(datasets)[:,-1]  #标签\n",
    "        data=data[:,:-1]  #去掉标签\n",
    "        \n",
    "        self.K=len(np.unique(label))  #类别个数\n",
    "        m=len(data)   #样本个数\n",
    "        self.trees=np.zeros((self.n_trees,self.K)).tolist()\n",
    "        \n",
    "        #计算每个类别占比\n",
    "        label_dict=pd.value_counts(label,normalize=True).to_dict()\n",
    "        #独热编码\n",
    "        y=OneHotEncoder(sparse = False).fit_transform(label.reshape(-1,1))\n",
    "        \n",
    "        #初始化F\n",
    "        F=np.zeros((m,self.K))\n",
    "        for i in range(self.K):\n",
    "            F[:,i]=[label_dict[i]]*m\n",
    "        \n",
    "        tree=CARTRegressor(min_samples_leaf=self.min_samples_leaf,max_depth=self.max_depth,is_gradient=True,K=self.K)\n",
    "        for i in range(self.n_trees):\n",
    "            P=np.exp(F)\n",
    "            P=P/np.sum(P,axis=1).reshape(-1,1)\n",
    "            for k in range(self.K):\n",
    "                yk=y[:,k]-P[:,k]\n",
    "                next_data=np.hstack((data,yk.reshape(-1,1)))\n",
    "                \n",
    "                self.trees[i][k]=CARTRegressor(min_samples_leaf=self.min_samples_leaf,max_depth=self.max_depth,is_gradient=True,K=self.K)\n",
    "                self.trees[i][k].fit(next_data)\n",
    "\n",
    "                gamma_index_list=self.trees[i][k].root.print_leaf_node()  #经决策树拟合后各叶子节点最佳负梯度拟合值及包含样本的index\n",
    "                gammas=[x[0] for x in gamma_index_list]\n",
    "                index_list=[x[1] for x in gamma_index_list]\n",
    "                \n",
    "                #更新F的k列\n",
    "                for index,gamma in zip(index_list,gammas):\n",
    "                    #index=index_list[i]\n",
    "                    #gamma=gammas[i]\n",
    "                    for j in range(len(index)):\n",
    "                        F[index[j],k]=F[index[j],k]+self.learning_rate*gamma\n",
    "\n",
    "    def predict(self,data):\n",
    "        m=len(data)  #样本个数\n",
    "        F=np.zeros((m,self.K))\n",
    "        for i in range(self.n_trees):\n",
    "            for k in range(self.K):\n",
    "                F[:,k]=F[:,k]+self.learning_rate*self.trees[i][k].predict(data)\n",
    "        P=np.exp(F)\n",
    "        P=P/np.sum(P,axis=1).reshape(-1,1)\n",
    "        y_pre=np.argmax(P,axis=1)\n",
    "        return y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================GBDT分类结果================================\n",
      "[0 2 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "datasets = [[6,0],\n",
    "           [12,0],\n",
    "           [14,0],\n",
    "           [18,0],\n",
    "           [20,0],\n",
    "           [65,1],\n",
    "           [31,1],\n",
    "           [40,1],\n",
    "           [1,1],\n",
    "           [2,1],\n",
    "           [100,2],\n",
    "           [101,2],\n",
    "           [65,2],\n",
    "           [54,2]]\n",
    "\n",
    "print('================================GBDT分类结果================================')\n",
    "model=GBDTClassfier(n_trees=5,min_samples_leaf=1,max_depth=2)\n",
    "model.fit(datasets)\n",
    "X_test=[[25],[100],[10],[900],[-10]]\n",
    "pred=model.predict(X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================GBDT分类结果_sklearn实现================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1454: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "print('================================GBDT分类结果_sklearn实现================================')\n",
    "gbdt = GradientBoostingClassifier(loss='deviance', learning_rate=1, min_samples_leaf=1, max_depth=2,\n",
    "                                  init=None, random_state=None,verbose=0, max_leaf_nodes=None,)\n",
    "\n",
    "X,y=np.array(datasets)[:,:-1],np.array(datasets)[:,-1:]\n",
    "gbdt.fit(X,y)\n",
    "pred = gbdt.predict(X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
