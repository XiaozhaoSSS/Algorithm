{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#采用朴素贝叶斯实现侮辱性言论分类\n",
    "\n",
    "class NaiveBayes():\n",
    "    def __init__(self):\n",
    "        self.p=None\n",
    "    def get_word_list(datasets):\n",
    "        #获得单词列表\n",
    "        datasets=np.array(datasets)\n",
    "        datasets=datasets.flatten()\n",
    "        word_list=set(datasets)\n",
    "        return word_list\n",
    "    def fit(self,datasets,labels):\n",
    "        #计算条件概率分布\n",
    "        p0_cond,p1_cond={},{}  #类别0和类别1下的条件概率\n",
    "        \n",
    "        new_labels,new_datasets=[],[]\n",
    "        for label,data in zip(labels,datasets):\n",
    "            new_labels+= [label]*len(data)\n",
    "            new_datasets+=data\n",
    "        labels=new_labels\n",
    "        datasets=new_datasets\n",
    "        \n",
    "        num0,num1=Counter(labels)[0],Counter(labels)[1]\n",
    "        p0,p1=num0/len(labels),num1/len(labels)    #类别0和类别1的先验概率\n",
    "\n",
    "        for word,label in zip(datasets,labels):\n",
    "            if label==0:p0_cond[word]=p0_cond.get(word,0)+1\n",
    "            else:p1_cond[word]=p1_cond.get(word,0)+1\n",
    "        #print(p0,p1,'侮辱言论',p0_cond,'非侮辱言论',p1_cond)\n",
    "        for word in p0_cond:\n",
    "            p0_cond[word]/=num0\n",
    "        for word in p1_cond:\n",
    "            p1_cond[word]/=num1\n",
    "            \n",
    "        self.p=[p0,p1,p0_cond,p1_cond]\n",
    "        \n",
    "        return p0,p1,p0_cond,p1_cond\n",
    "\n",
    "    def predict_proba(self,datasets):\n",
    "        p0,p1,p0_cond,p1_cond=self.p[0],self.p[1],self.p[2],self.p[3]\n",
    "        p_res=[]  #保存当前句子每个单词类别为0和1的后验概率\n",
    "        for data in datasets:\n",
    "        \n",
    "            pred0,pred1=0,0\n",
    "            for word in data:\n",
    "                #if p0_cond.get(word):pred0.append(p0_cond.get(word))\n",
    "                #if p1_cond.get(word):pred1.append(p1_cond.get(word))\n",
    "                pred0+=p0_cond.get(word,0)\n",
    "                pred1+=p1_cond.get(word,0)\n",
    "            p_res.append([pred0,pred1])\n",
    "        return  p_res\n",
    "\n",
    "    def predict(self,datasets):\n",
    "        p_res=self.predict_proba(datasets)\n",
    "        return np.argmax(p_res,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = [\n",
    "        ['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
    "        ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "        ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "        ['stop', 'posting', 'stupid', 'worthless', 'gar e'],\n",
    "        ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "        ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "labels = [0, 1, 0, 1, 0, 1]  # 1 is 侮辱性的文字, 0 is not\n",
    "\n",
    "model=NaiveBayes()\n",
    "model.fit(datasets,labels)\n",
    "model.predict([['love', 'my', 'dalmation'],['stupid', 'garbage'],['my', 'dog', 'has', 'flea'],['my']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
