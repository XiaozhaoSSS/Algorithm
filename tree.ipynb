{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def display(self):\n",
    "        '''\n",
    "        将树打印出来'''\n",
    "        def dfs(node):\n",
    "            print(node)\n",
    "            if not node:return\n",
    "            res={'label':node.label,'feature':node.feature,'tree':{}}\n",
    "            for next_node in node.tree:\n",
    "                res['tree'][next_node]=dfs(node.tree[next_node])\n",
    "            return res\n",
    "        return dfs(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from abc import abstractmethod\n",
    "import operator\n",
    "\n",
    "# 定义节点类\n",
    "class DecisionTreeNode:\n",
    "    def __init__(self,  label=None, feature_name=None, feature=None):\n",
    "        self.label = label\n",
    "        self.feature_name = feature_name\n",
    "        self.feature = feature\n",
    "        self.tree = {}\n",
    "    \n",
    "    def feature_name(self):\n",
    "        return self.feature_name_list(self.feature)\n",
    "    \n",
    "    def display(self,feature_name_list=None):\n",
    "        '''\n",
    "        将树打印出来'''\n",
    "        if feature_name_list:featurename=feature_name_list[self.feature] if self.feature else None\n",
    "        else:featurename=self.feature\n",
    "        res={'label':self.label,'feature':featurename,'tree':{}}\n",
    "        for next_node in self.tree:\n",
    "            res['tree'][next_node]=self.tree[next_node].display(feature_name_list)\n",
    "        return res\n",
    "\n",
    "class BaseDecisionTree:\n",
    "    def __init__(self,epsilon=1e-3):\n",
    "        self.root=None\n",
    "        self.epsilon=epsilon\n",
    "    '''\n",
    "    @abstractmethod\n",
    "    def __init__(self,\n",
    "                 criterion,\n",
    "                 splitter,\n",
    "                 max_depth,\n",
    "                 min_samples_split,\n",
    "                 min_samples_leaf,\n",
    "                 min_weight_fraction_leaf,\n",
    "                 max_features,\n",
    "                 max_leaf_nodes,\n",
    "                 random_state,\n",
    "                 min_impurity_decrease,\n",
    "                 min_impurity_split,\n",
    "                 class_weight=None,\n",
    "                 presort=False):\n",
    "        self.criterion = criterion\n",
    "        self.splitter = splitter\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.min_impurity_split = min_impurity_split\n",
    "        self.class_weight = class_weight\n",
    "        self.presort = presort\n",
    "'''\n",
    "    @staticmethod\n",
    "    def entropy(data):\n",
    "        '''\n",
    "        输入数据data,输出其经验熵'''\n",
    "        n=len(data)   #数据个数\n",
    "        label_dict={}\n",
    "        for i in range(n):\n",
    "            label_dict[data[i][-1]]=label_dict.get(data[i][-1],0)+1\n",
    "        k=len(label_dict)  #类别个数\n",
    "        ent=0\n",
    "        for n_k in label_dict.values():\n",
    "            ent+= n_k/n * math.log(n_k/n,2)\n",
    "        return -ent\n",
    "    \n",
    "    @staticmethod\n",
    "    def conditional_entropy(data,a):\n",
    "        '''\n",
    "        输入数据data和用来分类的特征a(即数据的第a列),输出条件熵'''\n",
    "        n=len(data)   #数据个数\n",
    "        con_ent=0\n",
    "        new_data=BaseDecisionTree.data_divide(data,a)\n",
    "        for curr_data in new_data:\n",
    "            con_ent+= len(curr_data)/n * BaseDecisionTree.entropy(curr_data)        \n",
    "        return con_ent\n",
    "    \n",
    "    @staticmethod\n",
    "    def data_divide(data,a):\n",
    "        '''\n",
    "        根据第a列特征将数据划分'''\n",
    "        new_data={}\n",
    "        for curr_data in data:\n",
    "            new_data[curr_data[a]]=new_data.get(curr_data[a],[])\n",
    "            new_data[curr_data[a]].append(curr_data)\n",
    "        return list(new_data.values())\n",
    "    \n",
    "    @staticmethod\n",
    "    def most_class(data):\n",
    "        '''\n",
    "        返回数据集中实例数最多的类'''\n",
    "        n=len(data)   #数据个数\n",
    "        label_dict={}\n",
    "        for i in range(n):\n",
    "            label_dict[data[i][-1]]=label_dict.get(data[i][-1],0)+1\n",
    "        m=0\n",
    "        for key in label_dict.keys():\n",
    "            if label_dict[key]>m:\n",
    "                m=label_dict[key]\n",
    "                res=key\n",
    "        return res\n",
    "    \n",
    "    def predict(self,data):\n",
    "        pre=[]\n",
    "        for curr_data in data:\n",
    "            curr_node=self.root\n",
    "            while curr_node.tree:\n",
    "                curr_node=curr_node.tree[curr_data[curr_node.feature]]\n",
    "            pre.append(curr_node.label)\n",
    "        return pre\n",
    "    \n",
    "class ID3(BaseDecisionTree):       \n",
    "    def fit(self,data):\n",
    "        def dfs(new_data,feature_list):  #递归创建树\n",
    "            if len(set([x[-1] for x in new_data]))==1:  #当前数据集所有实例都属于同一类\n",
    "                new_node=DecisionTreeNode()\n",
    "                new_node.label=ID3.most_class(new_data)\n",
    "                return new_node\n",
    "            \n",
    "            best_feature_index,information_gain=self.chooseBestFeature(new_data)  #选取最优的特征\n",
    "            best_feature=feature_list[best_feature_index]\n",
    "\n",
    "            if information_gain<self.epsilon:   #当信息增益小于阈值epsilon时停止\n",
    "                return  None\n",
    "            \n",
    "            new_node=DecisionTreeNode()\n",
    "            new_node.feature=best_feature\n",
    "            new_node.label=ID3.most_class(new_data)\n",
    "            \n",
    "            next_data_list=ID3.data_divide(new_data,best_feature)  #用最优的特征划分当前数据集\n",
    "            for next_data in next_data_list:  #对划分后的每个新数据集递归创建树\n",
    "                feature_value=next_data[0][best_feature_index]  #最优特征在当前数据集中的取值\n",
    "                if len(feature_list)>1:\n",
    "                    new_node.tree[feature_value]=dfs(\n",
    "                        [x[:best_feature_index]+x[best_feature_index+1:] for x in next_data],\n",
    "                        feature_list[:best_feature_index]+feature_list[best_feature_index+1:])\n",
    "                else:new_node.tree[feature_value]=DecisionTreeNode(label=ID3.most_class(next_data))\n",
    "\n",
    "            return new_node\n",
    "        self.root=dfs(data,list(range(len(data[0])-1)))\n",
    "        \n",
    "        return self.root\n",
    "    \n",
    "    def chooseBestFeature(self,data):#选取最优的特征\n",
    "        \n",
    "        ent=ID3.entropy(data)  #数据集的经验熵\n",
    "        n_features=len(data[0])-1  #特征个数\n",
    "        information_gain_list=[]  #每个特征对数据集的信息增益\n",
    "        for i in range(n_features):\n",
    "            information_gain_list.append(ent-ID3.conditional_entropy(data,i))\n",
    "        #获取最大的信息增益对应的特征索引及信息增益值\n",
    "        #print(\"ent,information_gain_list\",ent,information_gain_list)\n",
    "        min_index, min_number = max(enumerate(information_gain_list), key=operator.itemgetter(1))  \n",
    "        return min_index, min_number\n",
    "    \n",
    "class C45(ID3):       \n",
    "\n",
    "    def chooseBestFeature(self,data):#选取最优的特征\n",
    "        \n",
    "        ent=ID3.entropy(data)  #数据集的经验熵\n",
    "        n_features=len(data[0])-1  #特征个数\n",
    "        n=len(data)  #数据个数\n",
    "        information_gain_ratio_list=[]  #每个特征对数据集的信息增益比\n",
    "        for i in range(n_features):\n",
    "            \n",
    "            split_data=ID3.data_divide(data,i)  #按当前特征划分数据集\n",
    "            h=-sum([len(x)/n * math.log(len(x)/n,2) for x in split_data])  #数据集关于当前特征的值的熵\n",
    "            \n",
    "            information_gain_ratio_list.append((ent-ID3.conditional_entropy(data,i))/h)\n",
    "        \n",
    "        #获取最大的信息增益比对应的特征索引及信息增益比的值\n",
    "        min_index, min_number = max(enumerate(information_gain_ratio_list), key=operator.itemgetter(1))  \n",
    "        return min_index, min_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': '是是', 'feature': '有自己的房子', 'tree': {'否': {'label': '否否', 'feature': '有工作', 'tree': {'否': {'label': '否否', 'feature': None, 'tree': {}}, '是': {'label': '是是', 'feature': None, 'tree': {}}}}, '是': {'label': '是是', 'feature': None, 'tree': {}}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['否否']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = [['青年', '否', '否', '一般', '否否'],\n",
    "           ['青年', '否', '否', '好', '否否'],\n",
    "           ['青年', '是', '否', '好', '是是'],\n",
    "           ['青年', '是', '是', '一般', '是是'],\n",
    "           ['青年', '否', '否', '一般', '否否'],\n",
    "           ['中年', '否', '否', '一般', '否否'],\n",
    "           ['中年', '否', '否', '好', '否否'],\n",
    "           ['中年', '是', '是', '好', '是是'],\n",
    "           ['中年', '否', '是', '非常好', '是是'],\n",
    "           ['中年', '否', '是', '非常好', '是是'],\n",
    "           ['老年', '否', '是', '非常好', '是是'],\n",
    "           ['老年', '否', '是', '好', '是是'],\n",
    "           ['老年', '是', '否', '好', '是是'],\n",
    "           ['老年', '是', '否', '非常好', '是是'],\n",
    "           ['老年', '否', '否', '一般', '否否'],\n",
    "           ]\n",
    "labels = [u'年龄', u'有工作', u'有自己的房子', u'信贷情况', u'类别']\n",
    "\n",
    "tree=C45()\n",
    "tree.fit(datasets)\n",
    "print(tree.root.display(labels))\n",
    "\n",
    "tree.predict([['老年', '否', '否', '一般']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': '是是', 'feature': '有自己的房子', 'tree': {'否': {'label': '否否', 'feature': '有工作', 'tree': {'否': {'label': '否否', 'feature': None, 'tree': {}}, '是': {'label': '是是', 'feature': None, 'tree': {}}}}, '是': {'label': '是是', 'feature': None, 'tree': {}}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['否否']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree=ID3()\n",
    "tree.fit(datasets)\n",
    "print(tree.root.display(labels))\n",
    "\n",
    "tree.predict([['老年', '否', '否', '一般']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
